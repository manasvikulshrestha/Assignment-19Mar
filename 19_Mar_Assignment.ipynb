{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51fa69b1-0718-45eb-815a-194419bd89d4",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n",
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.\n",
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n",
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.\n",
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.\n",
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.\n",
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1.\n",
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5742a8-426f-42aa-ac4e-96b7376375e9",
   "metadata": {},
   "source": [
    "Q1. Min-Max scaling is a data preprocessing technique used to scale numeric features to a specific range, typically between 0 and 1. It works by subtracting the minimum value from each observation and then dividing by the range (the maximum value minus the minimum value). This ensures that all features are on the same scale, which can be important for certain algorithms that are sensitive to feature scales, such as neural networks and support vector machines.\n",
    "\n",
    "Example:\n",
    "Suppose you have a dataset with a feature \"age\" ranging from 20 to 60 years. After applying Min-Max scaling, the feature values will be transformed to a range between 0 and 1, preserving the relative differences between the values.\n",
    "\n",
    "Q2. The Unit Vector technique, also known as normalization, scales each feature independently to have a unit norm (length 1). Unlike Min-Max scaling, which transforms values to a specific range, normalization focuses on the direction of the data points in feature space rather than their magnitude.\n",
    "\n",
    "Example:\n",
    "Consider a dataset with two features, \"height\" and \"weight.\" After applying Unit Vector scaling, each data point's feature vector will be scaled such that its Euclidean length (norm) is 1, while the direction of the vector remains unchanged.\n",
    "\n",
    "Q3. PCA (Principal Component Analysis) is a dimensionality reduction technique used to identify patterns in high-dimensional data and express them in terms of new, orthogonal variables called principal components. It does this by transforming the original variables into a new set of variables, which are linear combinations of the original variables, ordered by the amount of variance they explain.\n",
    "\n",
    "Example:\n",
    "In a dataset with multiple correlated features such as height, weight, and age, PCA can identify the principal components that capture the most significant variations in the data, allowing for dimensionality reduction while preserving most of the variability.\n",
    "\n",
    "Q4. PCA can be used for feature extraction by transforming the original features into a smaller set of principal components that retain most of the variability in the data. These principal components can then be used as features in machine learning models.\n",
    "\n",
    "Example:\n",
    "Suppose you have a dataset with multiple features representing different aspects of a car (e.g., horsepower, engine displacement, weight). By applying PCA, you can extract principal components that represent combinations of these features, such as overall performance or efficiency, which can be more informative for predicting car prices.\n",
    "\n",
    "Q5. In the food delivery service recommendation system project, Min-Max scaling can be used to preprocess features like price, rating, and delivery time. By scaling these features to a range between 0 and 1, you ensure that they are on the same scale, preventing certain features from dominating others in the modeling process due to their larger magnitude.\n",
    "\n",
    "Q6. In the stock price prediction project, PCA can be used to reduce the dimensionality of the dataset containing various features like company financial data and market trends. By identifying the principal components that capture the most significant variations in the data, PCA allows for a more compact representation of the information while retaining most of its variability, which can improve the efficiency of the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3d406b-fb47-446a-ab83-ed461fe18829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Values: [-1.         -0.57894737 -0.05263158  0.47368421  1.        ]\n",
      "Number of Principal Components: 2\n",
      "Principal Components:\n",
      "[[-0.46777446 -0.85704616]\n",
      " [ 1.17551445  1.17162415]\n",
      " [-2.72712685 -0.80082314]\n",
      " [ 3.04878143 -0.84880437]\n",
      " [-1.02939457  1.33504952]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Q7: Perform Min-Max scaling\n",
    "data = np.array([1, 5, 10, 15, 20]).reshape(-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(\"Scaled Values:\", scaled_data.flatten())\n",
    "\n",
    "# Q8: Perform Feature Extraction using PCA\n",
    "# Assuming you have a dataset with features height, weight, age, gender, blood pressure\n",
    "# Create a sample dataset\n",
    "dataset = np.array([\n",
    "    [170, 65, 30, 1, 120],\n",
    "    [175, 70, 35, 0, 130],\n",
    "    [160, 55, 25, 1, 110],\n",
    "    [180, 80, 40, 1, 140],\n",
    "    [165, 60, 28, 0, 125]\n",
    "])\n",
    "\n",
    "# Standardize the data\n",
    "mean = np.mean(dataset, axis=0)\n",
    "std_dev = np.std(dataset, axis=0)\n",
    "standardized_data = (dataset - mean) / std_dev\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca.fit(standardized_data)\n",
    "\n",
    "# Determine the number of principal components to retain\n",
    "variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance_ratio = np.cumsum(variance_ratio)\n",
    "num_components = np.argmax(cumulative_variance_ratio >= 0.95) + 1  # Retain components explaining 95% variance\n",
    "\n",
    "# Perform PCA with chosen number of components\n",
    "pca = PCA(n_components=num_components)\n",
    "principal_components = pca.fit_transform(standardized_data)\n",
    "\n",
    "print(\"Number of Principal Components:\", num_components)\n",
    "print(\"Principal Components:\")\n",
    "print(principal_components)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
